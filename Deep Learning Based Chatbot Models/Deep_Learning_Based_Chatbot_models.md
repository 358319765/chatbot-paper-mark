# 论文阅读笔记【1】：基于深度学习的聊天机器人模型

## 一、文章相关情况

最近要做聊天机器人相关的项目，于是想找一些聊天机器人的综述文章。正好看到了这篇文章**基于深度学习的聊天机器人模型**（[Deep Learning Based Chatbot Models](https://arxiv.org/abs/1908.08835)），是2019年发布的，看起来还比较新，所以大概能代表最近的一些最新的研究进展，以下做一点小小的笔记。

## 二、摘要

- Modeling conversation是自然语言处理（NLP）和人工智能（AI）的一个重要的任务。
- 在过去，聊天机器人以来手写的规则、模板或者一些简单地统计学模型。

- 2015年左右这些模型被端对端可训练的神经网络（end-to-end trainable neural networks）取代。
- 循环编解码器模型（the recurrent encoder-decoder model [Cho et al., 2014]）主宰了对话模型（conversational modeling）任务。
- 那时起，a multitude of variations [Serban et al., 2016]和特征被提出，增强了聊天机器人产生的对话。
- 作者在阅读大量文献后认为，普通的对话领域需要不同于目前最新架构的方法。（the very nature of the general conversation domain demands approaches that are different from current state-of-art architectures.）
- 作者展示了为什么目前的聊天机器人模型在生成回答时难以考虑足够的前提（priors），以及这个如何影响对话的质量的。
- 在聊天机器人中，这些前提可能是一些对话依赖的外部信息，像聊天者的身份（persona）以及心情。（these priors can be outside sources of information that the conversation is conditioned on like the persona [Li et al., 2016a] or mood of the conversers.）
- 作者还会谈及最近的Transformer [Vaswani et al., 2017]在聊天机器人领域的应用。
- 作者使用的数据集是Cornell Movie-Dialog Corpus。
- 作者将问题视为一个编解码器来增强了初始的Transformer模型，作者增加了心情或者身份等信息到原对话数据中。
- 最后作者展示了一个很详细的分析，如何原始模型应用到对话数据。

## 三、论文目录

### 1 引入
  聊天机器人是一种可以用自然语言与人类交流的软件。从人工智能的诞生开始，将对话模型化仍是此领域的最为困难的挑战。尽管效果不尽人意，聊天机器人仍有着许多的应用，如Siri,Google Assistant和Cortana。为了完全理解现在的聊天机器人的适用性和限制，一项深度调查被完成了。在调查中，最近三年内的相关文章都被检查过，并用谈话语料训练了一个最近被发明的神经网络模型。
  
  论文的第二章简短的概览了聊天机器人的历史作为开头，并在此讨论了对话模型的性能和目标。在2.2章里展示了早期的一些方法，现在主流的建立于神经网络上的构建聊天机器人的模型则在2.3章中。
  
  第3章描述了过去三年里发展出的结构和技巧。这些刊物因为使用的方法或技巧不同，被作者分成了几组。在3.4章写了对于一些模型的性能的批评，展示了一些在建立对话模型时的不恰当的技巧。
  
  下一章（第4章）初步实验训练了一个基于神经网络的模型，the Transformer [Vaswani et al., 2017]，使用了dialog datasets [Danescu-
Niculescu-Mizil and Lee, 2011, Tiedemann, 2009, Lison and Tiedemann, 2016]。使用这些训练集作者进行了一些不同的训练，具体信息在4.3章。在第5章，这些训练设置的结果与大量的先前的聊天机器人模型相比较，比较使用的是标准的评估指标。

  最终，在第6章提供了之后的可能研究方向。具体来说，提出了些用于补救第3.4章所提出的问题的想法，并讨论了未来的研究方向。

### 2 聊天机器人的历史

#### 2.1 对话模型

- 聊天机器人模型通常把用户的自然语言对话作为输入，把回复作为输出
- 对于生成回答，有两种主要方法：
- - 传统的方法是用一些硬编码和规则来创建聊天机器人。（2.2中展示）
- - 更加神奇的方法可能是塑造于深度学习的崛起。（2.3中展示）
- 模型也可以容纳语音或者视觉输入
- 他们时常利用语音识别模块(speech recognition component)来将演讲转换为文本[Serban et al., 2017b]或者利用卷积神经网络(Convolutional neural networks) [Krizhevsky et al., 2012]将输入的图来转换为一种对于聊天机器人非常有用的表示(representations) [Havrylov and Titov, 2017]。
- 后面的模型又被叫做视觉对话器(visual dialog agents)，这个模型的对话基于文本和视觉的输入[Das et al., 2017]。
- 对话器(Conversational agents)有两种主要的形式。
- - 第一种是更加传统的面向任务的对话系统。面向任务就限制了他的对话能力，但是他在执行特定任务的命令和需求的时候非常鲁棒(robust)。经常，这种系统在执行任务的时候采取在知识库中检索的方法。这种系统的主要任务是代替通过菜单和用户界面的导航操作。
- - 第二种对话器是非任务的或者说是开放领域的聊天机器人。这些对话系统尝试在所有方面模拟人类，但是当前的模型距离这个目标仍非常遥远。人们通常从电影剧本或者是像Twitter一样的推-回对(post-reply pairs)里面提取对话样例[Vinyals and Le, 2015, Shang et al., 2016, Li et al., 2016a]。对于这些模型来说，他们没有一个被很好定义的目标任务，但是他们需要有一定量的对于世界的知识和常识推理能力来掌控任意话题的对话。
- 最近提出了一种想法是结合这两种对话器。主要想法是结合两种模型的好的方面，像面向目标的对话系统的鲁棒性以及像人类说闲话一样的开放领域的聊天机器人[Zhao et al., 2017a, Yu et al., 2017, Serban et al., 2017b]。这非常有意义，因为如果面向任务的对话系统更自然，并且能非常好解决特定领域的回复的话，用户会更可能使用这个。

#### 2.2 早期的方法

#### 2.3 编解码模型

基于规则的方法与基于神经网络的方法在观点上的不同在于后者拥有学习算法。传统机器学习和深度学习之间有重要的区别，后者是前者的一个子领域。在本文，仅讨论了应用于聊天机器人的深度学习方法，因为神经网络一直是会话建模的基础，而传统的机器学习方法极少的被用作补充。

当将神经网络应用于自然语言处理（NLP）任务时，每个单词（符号）都必须转换为数字表示形式[Bengio et al., 2003]。这是通过词嵌入来完成的，词嵌入将每个词表示为固定大小的实向量。词嵌入很有用，因为可以将单词表示为低得多的维度，而不是将它们作为有着词典大小的巨大矢量处理。NLP任务中使用的词典在2.3.4节中有更详细的介绍。 词嵌入在大量的自然语言数据上进行训练，目标是建立可以捕获单词之间的语义相似性的向量表示。更具体地说，因为相似的上下文通常有相似的含义，所以具有相似分布的单词应具有相似的向量表示。这个观点被称为the Distributional Hypothesis [Harris, 1954]。每个代表单词的向量都可以视为一组参数，这些参数可以一起用于训练神经网络的参数，也可以预先学习，这种方法在3.2.2节中介绍了。

不同于手写的规则，深度学习模型可以直接利用矩阵的乘法和非线性函数，由输入语句得到结果，而模型中可达数百万个参数。基于神经网络的会话模型可以进一步分为两类：基于检索的模型和生成模型。

* 基于检索的模型：从数据库中寻找最佳答案，评判标准可为神经网络[Cho et al., 2014]或输入话语与回答的cosine相似度。

* 生成模型：逐词生成，计算全词典内词语的可能性[Sutskever et al., 2014, Vinyals and Le, 2015]。

* 投票：通过上两个模型各自得到答案，再选择最好的答案 [Song et al.,2016]。

会话模型受深度学习方法的崛起而有所改变

* 编解码循环神经网络（RNN,也被称为seq2seq [Sutskever et al., 2014]，发明者为 [Cho et al., 2014])和它的变体是目前的主流。对RNN的概括介绍在2.3.1节，seq2seq具体内容在2.3.2节。

* RNN模型最初用于神经机器翻译(NMT)，但后来发现适用于在对话场景中将问题*翻译*为回答[Shang et al., 2015, Vinyals and Le, 2015]

* 尽管此领域较新，已经有人尝试建立统一的对话平台来对模型进行训练和评估[Miller et al., 2017]。

##### 2.3.1 循环神经网络

##### 2.3.2 Seq2seq模型

##### 2.3.3 深度Seq2seq模型

##### 2.3.4 解码和词汇

### 3 背景

#### 3.1 关于编解码模型更多的细节

##### 3.1.1 上下文

##### 3.1.2 目标方程

##### 3.1.3 评价方法

#### 3.2 对于编解码模型的增强

##### 3.2.1 注意力

##### 3.2.2 预训练

##### 3.2.3 附加的输入特征

##### 3.2.4 知识库和拷贝

#### 3.3 对对话模型不同的方法

##### 3.3.1 层级模型(Hierarchical Models)

##### 3.3.2 面向任务的对话系统

##### 3.3.3 强化学习

##### 3.3.4 不同的编解码模型

#### 3.4 讨论

##### 3.4.1 数据集

##### 3.4.2 损失函数

##### 3.4.3 内存

##### 3.4.4 评价度量

### 4 实验

#### 4.1  Transformer模型

##### 4.1.1 编解码网络

##### 4.1.2 注意力机制

##### 4.1.3 前向传播网络

##### 4.1.4 位置编码

##### 4.1.5 正则化和其他技巧

#### 4.2 数据集

##### 4.2.1 Cornell Movie-Dialog Corpus

##### 4.2.2 OpenSubtitles Corpus

#### 4.3 训练细节

##### 4.3.1 Tensor2Tensor

##### 4.3.2 Cornell Movie的训练

##### 4.3.3 带有说话者的Cornell Movie的训练

##### 4.3.4 OpenSubtitles训练

##### 4.3.5 用Cornell Movie数据微调后的OpenSubtitles训练

### 5 结果

#### 5.1 定量分析（Quantitative Analysis）

#### 5.2 定性分析（Qualitative Analysis）

### 6 将来的工作

#### 6.1 对于解决损失函数问题的想法

#### 6.2 时序调节以及内存（Temporal Conditioning and Memory）

#### 6.3 其他的想法

### 7 总结

## 四、论文正文

### 1、引入

- 首先
